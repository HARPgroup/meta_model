#!/bin/bash
if [ -z "$scenario" ]; then 
   # try to get from cmd args
   scenario=$1
   coverage=$2
   tempdir=$3
fi
export scenario coverage tempdir
if [ -z "$scenario" ]; then 
  echo "Error: missing Arguments."
  echo "Script must be called as: 'script_name scenario coverage_code [temp dir]'"
  echo "Ex: $0 PRISM usgs_ws_02031000"
  exit
fi
# create temp dir
if [ ! -d "$tempdir" ]; then
  mkdir $tempdir
fi
echo "Changing to working dir: $tempdir"
cd $tempdir

# the selected analysis model is set as a variable in the config file for the model scenario
GEO_MET_MODEL=`cbp get_config $scenario met GEO_MET_MODEL`
MET_DATA_SOURCE=`cbp get_config $scenario met MET_DATA_SOURCE`
MET_EXPORT_DIR=`cbp get_config $scenario met MET_EXPORT_DIR`
# Load simulation basics (need start date and translated datasource for raster.config)
START_DATE=`cbp get_config $scenario met START_DATE`
varkey=`cbp get_config $scenario met varkey`
#Get storm_volume variables from scenario config
SEARCH_ALL_STORM=`cbp get_config $scenario met SEARCH_ALL_STORM`
BASELINE_FLOW_METHOD=`cbp get_config $scenario met BASELINE_FLOW_METHOD`
STORM_INCLUDE_DURATION=`cbp get_config $scenario met STORM_INCLUDE_DURATION`
STORMSEP_REGRESSION_METHOD=`cbp get_config $scenario met STORMSEP_REGRESSION_METHOD`
STORMSEP_PLOT=`cbp get_config $scenario met STORMSEP_PLOT`

#Simple LM Expansion true/false
RATING_EXPANSION=`cbp get_config $scenario met RATING_EXPANSION`

#Set some variables to describe data structure used to store ratings:
COVERAGE_BUNDLE="watershed"
COVERAGE_FTYPE="usgs_full_drainage"
MET_MODEL_VERSION="met1.0"
SCENARIO_PROP_NAME="${GEO_MET_MODEL}"
RATINGS_VARKEY=`cbp get_config $scenario met RATINGS_VARKEY`
RATINGS_TODBASE_FILE="${tempdir}/${coverage}-ratingsdbase.csv"
RATINGS_SQL_FILE="${tempdir}/${coverage}-ratings.sql"

MET_SCRIPT_PATH="/opt/model/model_meteorology"

#DB Files:
RASTER_SQL_FILE="${tempdir}/${coverage}-${MET_DATA_SOURCE}-all.csv.sql"
RASTER_SUM_FILE="/tmp/${coverage}-${MET_DATA_SOURCE}-all.csv"

# Now, construct other variables given scenario config and arguments
COVERAGE_PRECIP_FILE="$MET_EXPORT_DIR/$scenario/precip/${coverage}_precip.csv"
WEEKLY_PRECIP_FILE="$MET_EXPORT_DIR/$scenario/precip/${coverage}_precip_weekly.csv"
DAILY_PRECIP_FILE="$MET_EXPORT_DIR/$scenario/precip/${coverage}_precip_daily.csv"
USGS_GAGE=`echo $coverage | sed 's/[^[:digit:]]\+//g'`
COVERAGE_FLOW_FILE="$MET_EXPORT_DIR/$scenario/flow/${coverage}-flow.csv"
RATING_FILE="$MET_EXPORT_DIR/${scenario}/out/${coverage}-ratings.csv"
RATING_TS_FILE="$MET_EXPORT_DIR/${scenario}/out/${coverage}-rating-ts.csv"
MODEL_JSON="$MET_EXPORT_DIR/$scenario/stats/${coverage}-model.json"
MODEL_STATS="$MET_EXPORT_DIR/$scenario/stats/${coverage}-stats.json"
RESID_PLOTS="$MET_EXPORT_DIR/$scenario/plots/residplots"

# Storm separation outputs:
STORM_EVENT_FLOW_FILE="$MET_EXPORT_DIR/$scenario/flow/${coverage}-stormevent-flow.csv"
STORM_EVENT_STATS_FILE="$MET_EXPORT_DIR/$scenario/flow/${coverage}-stormevent-stats.csv"
STORM_EVENT_PRECIP_PLOT_DIR="$MET_EXPORT_DIR/$scenario/plots/storm_plots"


# loads the base database specific config to get the db_host
db_config=`find_config db.config`
if [ "$db_config" = "" ]; then
  db_config="$META_MODEL_ROOT/models/raster_met/db.config"
fi
. $db_config
export db_host


export RASTER_SQL_FILE RASTER_SUM_FILE
export MET_SCRIPT_PATH MET_DATA_SOURCE MET_EXPORT_DIR GEO_MET_MODEL COVERAGE_PRECIP_FILE COVERAGE_FLOW_FILE WEEKLY_PRECIP_FILE 
export USGS_GAGE OBS_FLOW_FILE DAILY_PRECIP_FILE MODEL_JSON MODEL_STATS 
export RATING_TS_FILE RATING_FILE
export START_DATE varkey RESID_PLOTS
export STORM_EVENT_FLOW_FILE STORM_EVENT_STATS_FILE STORM_EVENT_PLOT_DIR STORM_EVENT_PRECIP_PLOT_DIR
export SEARCH_ALL_STORM BASELINE_FLOW_METHOD STORM_INCLUDE_DURATION STORMSEP_REGRESSION_METHOD STORMSEP_PLOT
export COVERAGE_BUNDLE COVERAGE_FTYPE MET_MODEL_VERSION SCENARIO_PROP_NAME RATINGS_VARKEY
export RATINGS_TODBASE_FILE RATINGS_SQL_FILE RATING_EXPANSION
