#!/bin/bash
# expects that datasource is defined
if [ -z ${ddate+x} ]; then 
  echo "Variable 'ddate' (download date) must be defined when calling raster.config. Exiting."
  exit
fi

db_host="dbase2"
if [ -z "$DB_HOST" ]; then
  dh_host=$DB_HOST # allow override with environment variable
fi
db_port="5432"
db_name="drupal.dh03"
tz=""
MET_SCRIPT_PATH="/opt/model/model_meteorology"
maskExtent='/backup/meteorology/cbp_extent.csv'
maskExtentLayer="cbp_extent"
yr=`date -d "$ddate" +%Y`
mo=`date -d "$ddate" +%m`
da=`date -d "$ddate" +%d`
jday=`date -d "$ddate" +%j`
ymd="$yr$mo$da"

src_files=""
import_files=""

#Send maskExtent to download functions
export maskExtent

echo "Loading config for $datasource"
case $datasource in
  PRISM)
  # BEGIN PRISM config
  declare -A config=(
   ["entity_type"]="dh_feature"
   ["ext"]="_CBP.gtiff"
   ["single_band"]="false"
   ["dt"]=86400
   ["scratchdir"]="/tmp"
   ["basedir"]="/backup/meteorology/PRISM"
   ["datasource"]="PRISM"
   ["dataset"]="PRISM_precip_"
   ["varkey"]="prism_mod_daily"
   ["extent_hydrocode"]="cbp6_met_coverage"
   ["extent_ftype"]="cbp_met_grid"
   ["TZ"]="GMT"
   ["TZ_HR"]=12
   ["TS_BAND"]='none'
   ["extent_bundle"]="landunit"
  )
  final_ext=${config["ext"]}
  base_dir=${config["basedir"]}
  src_dir="$base_dir/$yr/$jday"
  if [ -e $src_dir ]; then
    import_files=`ls $src_dir/*.gtiff | grep $final_ext`
    src_files=`ls $src_dir/*.bil`
  fi
  # END PRISM config
  ;;

  daymet)
  
  declare -A config=(
   ["basedir"]="/backup/meteorology/daymet"
   ["entity_type"]="dh_feature"
   ["ext"]="_CBP.gtiff"
   ["single_band"]="false"
   ["scratchdir"]="/tmp"
   ["dataset"]="daymet_precip_"
   ["datasource"]="daymet"
   ["varkey"]="daymet_mod_daily"
   ["extent_hydrocode"]="cbp6_met_coverage"
   ["extent_ftype"]="cbp_met_grid"
   ["extent_bundle"]="landunit"
   ["TZ"]="GMT"
   ["TZ_HR"]=12
   ["TS_BAND"]='none'
   ["dt"]=86400
  )
  
  #Get the bounding box of the user selected mask.
  #First, get the extent output from ogrinfo
  bboxExtent=`ogrinfo $maskExtent $maskExtentLayer | grep "Extent: "`
  
  #Use grep to get only the matching pattern (-o) via perl regular expression (-P) to identify the coordinates of the bounding box.
  #This returns both the east/west coordinate or the north AND south coordinates. We can use head/tail to just get the coordinate 
  #of interest for the array below
  #For the east and west coordinates, get the first or second number that matches a literal minus sign (-) followed 
  #by at least one digit possibly followed by a literal period (.) followed by potnetially more digits
  bboxwest=`echo $bboxExtent | grep -oP "\-[0-9]+[\.]?[0-9]*" | head -1`
  bboxeast=`echo $bboxExtent | grep -oP "\-[0-9]+[\.]?[0-9]*" | tail -1`
  #North and south coordinates are slighly more complicated as they are identified below using leading white space, that we remove via a second grep call
  bboxsouth=`echo $bboxExtent | grep -oP " [0-9]+[\.]?[0-9]*" | grep -oP "([0-9]+[\.]?[0-9]*){1}" | head -1`
  bboxnorth=`echo $bboxExtent | grep -oP " [0-9]+[\.]?[0-9]*" | grep -oP "([0-9]+[\.]?[0-9]*){1}" | tail -1`
  echo "Set extent of mask via $maskExtent as $bboxnorth $bboxsouth $bboxwest $bboxeast"
  
  #Set a variable for use in download functions for base directory. Need to set this for check below as well
  base_dir=${config["basedir"]}
  #Set the final file extension and ending suffix of final file name
  final_ext=${config["ext"]}
  #Set the source directory e.g. where files will live more permanantly after downloa dnad process
  src_dir="$base_dir/$yr/$jday"
  if [ -d "$base_dir/$yr" ]; then
    if [ -d "$base_dir/$yr/$jday" ]; then
	#Find the files to import into the psql database via raster2psql
    import_files=`ls $src_dir/*.gtiff | grep $final_ext`
	#Find the 'source' files that were downloaded from REST to be clipped and reprojected
    src_files=`ls $src_dir/*.bil`
    fi
  fi
  ;;
  

  nldas2)
  declare -A config=(
   ["entity_type"]="dh_feature"
   ["ext"]="_CBP.gtiff"
   ["dt"]=3600
   ["TZ"]="GMT"
   ["TZ_HR"]=12
   ["TS_BAND"]=10
   ["single_band"]=10
   ["scratchdir"]="/tmp"
   ["basedir"]="/backup/meteorology"
   ["datasource"]="nldas2"
   ["dataset"]="nldas2_precip_"
   ["varkey"]="nldas2_obs_hourly"
   ["extent_hydrocode"]="cbp6_met_coverage"
   ["extent_ftype"]="cbp_met_grid"
   ["extent_bundle"]="landunit"
  )
  # files to import can be inferred
  final_ext=${config["ext"]}
  base_dir=${config["basedir"]}
  echo "Looking for raster files in $base_dir/$yr/$jday"
  if [ -d "$base_dir/$yr" ]; then
    if [ -d "$base_dir/$yr/$jday" ]; then
      src_dir="$base_dir/$yr/$jday"
      src_files=`ls $src_dir/*.grb`
      # this will have a list of geotiff if the files have been processed
      # but will omit intermediates.
      import_files=`ls $src_dir/*.gtiff | grep $final_ext`
    fi
  fi
  ;;
esac

# create friendly names
datasource=${config["datasource"]}
extent_hydrocode=${config["extent_hydrocode"]}
extent_bundle=${config["extent_bundle"]}
varkey=${config["varkey"]}
extent_ftype=${config["extent_ftype"]}
entity_type=${config["entity_type"]}
# Note: in preliminary testing this did not lead to an appreciable increase in speed, approx 5% less time
single_band=${config["single_band"]}
tz_hr=${config["TZ_HR"]}
echo "Setting timezone hour to $tz_hr"
